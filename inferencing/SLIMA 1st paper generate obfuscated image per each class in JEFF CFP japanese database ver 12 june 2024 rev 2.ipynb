{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5a42476",
   "metadata": {},
   "source": [
    "TRAINING DATASET USADO ES LFW (Labeled Faces in the Wild https://vis-www.cs.umass.edu/lfw/ UMASS)\n",
    "\n",
    "INFERENCING DATASETS USED \n",
    "\n",
    "CFP DATASET, CELEBRITIES DATASET FACES FRONTAL AND PROFILE http://www.cfpw.io/ \n",
    "\n",
    "MIT CIBCL FACE RECOGNITION, SEVERAL CLASSES http://cbcl.mit.edu/software-datasets/heisele/facerecognition-database.html\n",
    "\n",
    "JEFF Japanese Female Facial expression FACE RECOGITION JAPAN https://zenodo.org/records/3451524\n",
    "\n",
    "CROSS AGE CELEBRITY DATASET https://www.v7labs.com/open-datasets/cacd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf5073a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7ddbfd-4285-499f-988d-597f17ebfa7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#SEEDING\n",
    "import random\n",
    "random.seed(42)  # Set the seed to a fixed number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a1625a-4216-4261-9547-0a936a7366c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1502c9103310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)  # Set the seed for PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c6b717b-7e78-4a8f-b7e4-c87b8f8e3c2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)  #1.11.0+cpu\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaecab3a-7028-4460-8998-5869d7c4aa98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 GPUs available\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"{torch.cuda.device_count()} GPUs available\")\n",
    "else:\n",
    "    print(\"Single GPU or no GPU available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e10bde-c085-4a8e-aa5f-cfc0e89c1416",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if GPU is available and move the model to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04e8fa3-3087-4d33-90ec-cb274bb4767b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# If using CUDA (PyTorch)\n",
    "torch.cuda.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)  # if you are using multi-GPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3beb43b2-98a2-4ed4-a645-5e0ee7ae6275",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enforce deterministic behavior in PyTorch (optional, may impact performance)\n",
    "# This is important for reproducibility, especially for certain operations on GPUs\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecabe1b-3e0d-40e3-bf1f-424c447c0658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27aa28f-8940-4c78-a4d0-19a3be06165d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rapids/notebooks/data/storage/slima'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install opencv-python-headless\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d35a47-9731-4503-ac01-c9c0a4e73e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Change the present working directory\n",
    "os.chdir('/home/rapids/notebooks/data/storage/slima')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58431d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=512\n",
    "n_classes=1\n",
    "#normalization size in pixels\n",
    "resizex=112\n",
    "resizey= 112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd0f1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the directory path\n",
    "# base_dir = r'D:\\JEFF face recognition db Japan\\jaffedbase'\n",
    "# output_dir = r'D:\\JEFF face recognition db Japan\\jaffedbase_obfuscated'\n",
    "# state_dict_path = r'D:\\JEFF face recognition db Japan\\fuzzyarcface_resnet101_customized5  tau 0.9 100 epochs fuzzymembership raw mask ones.pth'\n",
    "# arcface_state_dict_path = r'path\\to\\arcface_resnet101_customized4_tau_0.5_100_epochs.pth'\n",
    "\n",
    "\n",
    "# Set the directory path\n",
    "base_dir = 'jaffedbase'\n",
    "output_dir = 'jaffedbase_obfuscated'\n",
    "fuzzyarcface_state_dict_path = 'fuzzyarcface_resnet101_customized5  tau 0.9 100 epochs fuzzymembership raw mask ones.pth'\n",
    "arcface_state_dict_path = 'arcface_resnet101_customized4 tau 0.5 100 epochs.pth'\n",
    "\n",
    "\n",
    "# Set the directory path\n",
    "base_dir = 'jaffedbase'\n",
    "output_dir = 'JEFF face recognition db Japan\\jaffedbase_obfuscated'\n",
    "\n",
    "\n",
    "fuzzyarcface1_state_dict_path = 'fuzzyarcface_resnet101_customized5  tau 0.9 100 epochs fuzzymembership raw mask ones.pth'\n",
    "fuzzyarcface2_state_dict_path = 'fuzzyarcface_resnet101_customized4 tau 0.5 fuzzymembership raw mask ones.pth'\n",
    "fuzzyarcface3_state_dict_path = 'fuzzyarcface_resnet101_customized4 tau 0.1 100 epochs.pth'\n",
    "\n",
    "\n",
    "arcface_state_dict_path = 'arcface_resnet101_customized4 tau 0.5 100 epochs.pth'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46ac69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model creation function\n",
    "def create_base_model():\n",
    "    model = iresnet100()  # Ensure this is your actual model class\n",
    "    return model\n",
    "\n",
    "# Remove 'module.' prefix from keys if necessary\n",
    "def remove_module_prefix(state_dict):\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            new_state_dict[k[7:]] = v  # Remove 'module.' prefix\n",
    "        else:\n",
    "            new_state_dict[k] = v\n",
    "    return new_state_dict\n",
    "\n",
    "\n",
    "# # Define models for each training method\n",
    "# def create_base_model():\n",
    "#     model = iresnet100()\n",
    "#     if torch.cuda.device_count() > 1:\n",
    "#         model = torch.nn.DataParallel(model)\n",
    "#     return model\n",
    "\n",
    "# Assuming you have a function to remove 'module.' prefix if present\n",
    "# def remove_module_prefix(state_dict):\n",
    "#     return {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "# def remove_module_prefix(state_dict):\n",
    "#     new_state_dict = {}\n",
    "#     for k, v in state_dict.items():\n",
    "#         if k.startswith('module.'):\n",
    "#             new_state_dict[k[7:]] = v  # Remove 'module.' prefix\n",
    "#         else:\n",
    "#             new_state_dict[k] = v\n",
    "#     return new_state_dict\n",
    "\n",
    "\n",
    "# Function to obfuscate an image\n",
    "def obfuscate_image(image, obfuscation_level):\n",
    "    h, w = image.shape\n",
    "    mask = np.random.rand(h, w) < obfuscation_level\n",
    "    obfuscated_image = image.copy()\n",
    "    obfuscated_image[mask] = 0  # Set the obfuscated pixels to black (or you can use any other obfuscation method)\n",
    "    return obfuscated_image\n",
    "\n",
    "# Function to extract embedding using the model\n",
    "def extract_embedding(model, image, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image = transform(image).unsqueeze(0).to(device)\n",
    "        embedding = model(image).cpu().numpy().flatten()\n",
    "    return embedding\n",
    "\n",
    "# Function to compute cosine similarity\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "543b93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iRESNET100 IMPLEMENTATION\n",
    "\n",
    "\n",
    "__all__ = ['iresnet18', 'iresnet34', 'iresnet50', 'iresnet100', 'iresnet200']\n",
    "using_ckpt = False\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=dilation,\n",
    "                     groups=groups,\n",
    "                     bias=False,\n",
    "                     dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "class IBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None,\n",
    "                 groups=1, base_width=64, dilation=1):\n",
    "        super(IBasicBlock, self).__init__()\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        self.bn1 = nn.BatchNorm2d(inplanes, eps=1e-05,)\n",
    "        self.conv1 = conv3x3(inplanes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, eps=1e-05,)\n",
    "        self.prelu = nn.PReLU(planes)\n",
    "        self.conv2 = conv3x3(planes, planes, stride)\n",
    "        self.bn3 = nn.BatchNorm2d(planes, eps=1e-05,)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward_impl(self, x):\n",
    "        identity = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.prelu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        out += identity\n",
    "        return out        \n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training and using_ckpt:\n",
    "            return checkpoint(self.forward_impl, x)\n",
    "        else:\n",
    "            return self.forward_impl(x)\n",
    "\n",
    "\n",
    "class IResNet(nn.Module):\n",
    "    #fc_scale = 7 * 7  * 4  #for dim 224x 224\n",
    "    fc_scale = 7 * 7    #for dim 112x 112\n",
    "    \n",
    "    def __init__(self,\n",
    "                 block, layers, dropout=0, embedding_size=embedding_size, num_features=n_classes, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None, fp16=False):\n",
    "        super(IResNet, self).__init__()\n",
    "        self.extra_gflops = 0.0\n",
    "        self.fp16 = fp16\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes, eps=1e-05)\n",
    "        self.prelu = nn.PReLU(self.inplanes)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=2)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       128,\n",
    "                                       layers[1],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       256,\n",
    "                                       layers[2],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       512,\n",
    "                                       layers[3],\n",
    "                                       stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "        self.bn2 = nn.BatchNorm2d(512 * block.expansion, eps=1e-05,)\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=True)\n",
    "        self.fc = nn.Linear(512 * block.expansion * self.fc_scale, embedding_size)\n",
    "        self.features = nn.BatchNorm1d(embedding_size, eps=1e-05)\n",
    "        nn.init.constant_(self.features.weight, 1.0)\n",
    "        self.features.weight.requires_grad = False\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0, 0.1)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, IBasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion, eps=1e-05, ),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                  self.base_width, previous_dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(\n",
    "                block(self.inplanes,\n",
    "                      planes,\n",
    "                      groups=self.groups,\n",
    "                      base_width=self.base_width,\n",
    "                      dilation=self.dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.cuda.amp.autocast(self.fp16):\n",
    "            x = self.conv1(x)\n",
    "            x = self.bn1(x)\n",
    "            x = self.prelu(x)\n",
    "            x = self.layer1(x)\n",
    "            x = self.layer2(x)\n",
    "            x = self.layer3(x)\n",
    "            x = self.layer4(x)\n",
    "            x = self.bn2(x)\n",
    "            x = torch.flatten(x, 1)\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc(x.float() if self.fp16 else x)\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def _iresnet(arch, block, layers, pretrained, progress, **kwargs):\n",
    "    model = IResNet(block, layers, **kwargs)\n",
    "    if pretrained:\n",
    "        raise ValueError()\n",
    "    return model\n",
    "\n",
    "\n",
    "def iresnet18(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet18', IBasicBlock, [2, 2, 2, 2], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet34(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet34', IBasicBlock, [3, 4, 6, 3], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet50(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet50', IBasicBlock, [3, 4, 14, 3], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet100(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet100', IBasicBlock, [3, 13, 30, 3], pretrained,\n",
    "                    progress, **kwargs)\n",
    "\n",
    "\n",
    "def iresnet200(pretrained=False, progress=True, **kwargs):\n",
    "    return _iresnet('iresnet200', IBasicBlock, [6, 26, 60, 6], pretrained,\n",
    "                    progress, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3dbdc19-cfdc-49ac-befe-f1d93cd3ec03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Load the state_dict\n",
    "# fuzzyarcface1_state_dict = torch.load(fuzzyarcface1_state_dict_path, map_location=device)\n",
    "\n",
    "# # Remove the 'module.' prefix if necessary\n",
    "# fuzzyarcface1_state_dict = remove_module_prefix(fuzzyarcface1_state_dict)\n",
    "\n",
    "# fuzzyarcface1_model = create_base_model()\n",
    "\n",
    "# # Load the state_dict into the model\n",
    "# fuzzyarcface1_model.load_state_dict(fuzzyarcface1_state_dict)\n",
    "\n",
    "# # Move the model to the device\n",
    "# fuzzyarcface1_model.to(device)\n",
    "\n",
    "# # Wrap the model in DataParallel if multiple GPUs are available\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     fuzzyarcface1_model = torch.nn.DataParallel(fuzzyarcface1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2153ab36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create output directory if not exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Load the FuzzyArcface1 model\n",
    "#device = torch.device('gpu')\n",
    "fuzzyarcface1_model = create_base_model()\n",
    "fuzzyarcface1_state_dict = torch.load(fuzzyarcface1_state_dict_path, map_location=device)\n",
    "fuzzyarcface1_state_dict = remove_module_prefix(fuzzyarcface1_state_dict)\n",
    "fuzzyarcface1_model.load_state_dict(fuzzyarcface1_state_dict)\n",
    "fuzzyarcface1_model.to(device)\n",
    "# Wrap the model in DataParallel if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    fuzzyarcface1_model = torch.nn.DataParallel(fuzzyarcface1_model)\n",
    "    \n",
    "# Load the Arcface model\n",
    "arcface_model = create_base_model()\n",
    "arcface_state_dict = torch.load(arcface_state_dict_path, map_location=device)\n",
    "arcface_state_dict = remove_module_prefix(arcface_state_dict)\n",
    "arcface_model.load_state_dict(arcface_state_dict)\n",
    "arcface_model.to(device)\n",
    "# Wrap the model in DataParallel if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    arcface_model = torch.nn.DataParallel(arcface_model)\n",
    "    \n",
    "# Load the FuzzyArcface2 model\n",
    "fuzzyarcface2_model = create_base_model()\n",
    "fuzzyarcface2_state_dict = torch.load(fuzzyarcface2_state_dict_path, map_location=device)\n",
    "fuzzyarcface2_state_dict = remove_module_prefix(fuzzyarcface2_state_dict)\n",
    "fuzzyarcface2_model.load_state_dict(fuzzyarcface2_state_dict)\n",
    "fuzzyarcface2_model.to(device)\n",
    "# Wrap the model in DataParallel if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    fuzzyarcface2_model = torch.nn.DataParallel(fuzzyarcface2_model)\n",
    "\n",
    "# Load the FuzzyArcface3 model\n",
    "fuzzyarcface3_model = create_base_model()\n",
    "fuzzyarcface3_state_dict = torch.load(fuzzyarcface3_state_dict_path, map_location=device)\n",
    "fuzzyarcface3_state_dict = remove_module_prefix(fuzzyarcface3_state_dict)\n",
    "fuzzyarcface3_model.load_state_dict(fuzzyarcface3_state_dict)\n",
    "fuzzyarcface3_model.to(device)\n",
    "# Wrap the model in DataParallel if multiple GPUs are available\n",
    "if torch.cuda.device_count() > 1:\n",
    "    fuzzyarcface3_model = torch.nn.DataParallel(fuzzyarcface3_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d0db988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4aa04f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all image paths\n",
    "image_paths = glob(os.path.join(base_dir, '*.tiff'))\n",
    "\n",
    "# Dictionary to store class-wise images\n",
    "class_images = {}\n",
    "\n",
    "# Read images and group by class\n",
    "for image_path in image_paths:\n",
    "    image_name = os.path.basename(image_path)\n",
    "    class_name = image_name.split('.')[0]\n",
    "    if class_name not in class_images:\n",
    "        class_images[class_name] = []\n",
    "    class_images[class_name].append(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d27bc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fixed obfuscation levels\n",
    "obfuscation_levels = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "\n",
    "# DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=[\n",
    "    'Class', 'Obfuscation Level',\n",
    "    'FuzzyArcFace1 Similarity', 'ArcFace Similarity',\n",
    "    'FuzzyArcFace2 Similarity', 'FuzzyArcFace3 Similarity'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8735662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each class\n",
    "for class_name, images in class_images.items():\n",
    "    # Randomly pick one image per class\n",
    "    selected_image_path = random.choice(images)\n",
    "    selected_image = cv2.imread(selected_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Create class directory in the output directory\n",
    "    class_output_dir = os.path.join(output_dir, class_name)\n",
    "    if not os.path.exists(class_output_dir):\n",
    "        os.makedirs(class_output_dir)\n",
    "\n",
    "    # Save the original image in the class directory\n",
    "    original_image_name = os.path.basename(selected_image_path)\n",
    "    cv2.imwrite(os.path.join(class_output_dir, original_image_name), selected_image)\n",
    "\n",
    "    # Convert the original image to RGB PIL format\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(selected_image, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "    # Extract embeddings for the original image\n",
    "    original_fuzzyarcface1_embedding = extract_embedding(fuzzyarcface1_model, pil_image, device)\n",
    "    original_arcface_embedding = extract_embedding(arcface_model, pil_image, device)\n",
    "    original_fuzzyarcface2_embedding = extract_embedding(fuzzyarcface2_model, pil_image, device)\n",
    "    original_fuzzyarcface3_embedding = extract_embedding(fuzzyarcface3_model, pil_image, device)\n",
    "\n",
    "    # Generate and save obfuscated images, and compute similarity\n",
    "    for obfuscation_level in obfuscation_levels:\n",
    "        obfuscated_image = obfuscate_image(selected_image, obfuscation_level)\n",
    "        obfuscated_image_name = f\"{class_name}.obf{int(obfuscation_level*100)}.png\"\n",
    "        cv2.imwrite(os.path.join(class_output_dir, obfuscated_image_name), obfuscated_image)\n",
    "\n",
    "        # Convert the obfuscated image to RGB PIL format\n",
    "        pil_obfuscated_image = Image.fromarray(cv2.cvtColor(obfuscated_image, cv2.COLOR_GRAY2RGB))\n",
    "\n",
    "        # Extract embeddings for the obfuscated image\n",
    "        obfuscated_fuzzyarcface1_embedding = extract_embedding(fuzzyarcface1_model, pil_obfuscated_image, device)\n",
    "        obfuscated_arcface_embedding = extract_embedding(arcface_model, pil_obfuscated_image, device)\n",
    "        obfuscated_fuzzyarcface2_embedding = extract_embedding(fuzzyarcface2_model, pil_obfuscated_image, device)\n",
    "        obfuscated_fuzzyarcface3_embedding = extract_embedding(fuzzyarcface3_model, pil_obfuscated_image, device)\n",
    "\n",
    "        # Compute cosine similarities\n",
    "        fuzzyarcface1_similarity = cosine_similarity(original_fuzzyarcface1_embedding, obfuscated_fuzzyarcface1_embedding)\n",
    "        arcface_similarity = cosine_similarity(original_arcface_embedding, obfuscated_arcface_embedding)\n",
    "        fuzzyarcface2_similarity = cosine_similarity(original_fuzzyarcface2_embedding, obfuscated_fuzzyarcface2_embedding)\n",
    "        fuzzyarcface3_similarity = cosine_similarity(original_fuzzyarcface3_embedding, obfuscated_fuzzyarcface3_embedding)\n",
    "        \n",
    "        # Append results to DataFrame\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "            'Class': class_name,\n",
    "            'Obfuscation Level': obfuscation_level * 100,\n",
    "            'FuzzyArcFace1 Similarity': fuzzyarcface1_similarity * 100,\n",
    "            'ArcFace Similarity': arcface_similarity * 100,\n",
    "            'FuzzyArcFace2 Similarity': fuzzyarcface2_similarity * 100,\n",
    "            'FuzzyArcFace3 Similarity': fuzzyarcface3_similarity * 100\n",
    "        }])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e5eb773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Class, Obfuscation Level, FuzzyArcFace1 Similarity, ArcFace Similarity, FuzzyArcFace2 Similarity, FuzzyArcFace3 Similarity]\n",
      "Index: []\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(results_df)\n",
    "\n",
    "# Save results to a CSV file\n",
    "results_df.to_csv(os.path.join(output_dir, 'similarity_results_fuzzyall_crisp2.csv'), index=False)\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1fc20",
   "metadata": {},
   "source": [
    "CFP DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd996d5e",
   "metadata": {},
   "source": [
    "Load the images and randomly select one per class.\n",
    "Apply obfuscation at different levels.\n",
    "Use a pretrained model to extract embeddings and calculate similarity.\n",
    "Output the results in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "617f51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set paths and device\n",
    "base_dir_cfp = 'CFP DATASET/Data/Images'\n",
    "output_dir = 'CFP DATASET/Processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e32aaaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CFP DATASET/Data/Images'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Get all image paths\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m class_folders \u001b[38;5;241m=\u001b[39m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir_cfp, d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir_cfp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_dir_cfp, d))]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Prepare results dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObfuscation Level\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuzzyArcFace Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mArcFace Similarity\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CFP DATASET/Data/Images'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all image paths\n",
    "class_folders = [os.path.join(base_dir_cfp, d) for d in os.listdir(base_dir_cfp) if os.path.isdir(os.path.join(base_dir_cfp, d))]\n",
    "\n",
    "# Prepare results dataframe\n",
    "results_df = pd.DataFrame(columns=['Class', 'Obfuscation Level', 'FuzzyArcFace Similarity', 'ArcFace Similarity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dddd63f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to obfuscate image\n",
    "def obfuscate_image(image, obfuscation_level):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    width, height = image.size\n",
    "    num_obfuscation_points = int(obfuscation_level * width * height)\n",
    "    for _ in range(num_obfuscation_points):\n",
    "        x = random.randint(0, width - 1)\n",
    "        y = random.randint(0, height - 1)\n",
    "        draw.point((x, y), fill=\"black\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fd75a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf4703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for class_folder in class_folders:\n",
    "    class_name = os.path.basename(class_folder)\n",
    "    frontal_folder = os.path.join(class_folder, 'frontal')\n",
    "    image_files = glob(os.path.join(frontal_folder, '*.jpg'))\n",
    "\n",
    "    # Check if image_files list is empty\n",
    "    if not image_files:\n",
    "        print(f\"No images found in folder: {frontal_folder}\")\n",
    "        continue\n",
    "\n",
    "    selected_image_path = random.choice(image_files)\n",
    "    #selected_image = cv2.imread(selected_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    #pil_image = Image.fromarray(cv2.cvtColor(selected_image, cv2.COLOR_BGR2RGB))\n",
    "    selected_image = cv2.imread(selected_image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "\n",
    "    \n",
    "    # Create class directory in the output directory\n",
    "    class_output_dir = os.path.join(output_dir, class_name)\n",
    "    if not os.path.exists(class_output_dir):\n",
    "        os.makedirs(class_output_dir)\n",
    "\n",
    "    # Save the original image in the class directory\n",
    "    original_image_name = os.path.basename(selected_image_path)\n",
    "    cv2.imwrite(os.path.join(class_output_dir, original_image_name), selected_image)\n",
    "\n",
    "    # Convert the original image to RGB PIL format\n",
    "    #pil_image = Image.fromarray(cv2.cvtColor(selected_image, cv2.COLOR_GRAY2RGB))\n",
    "       # Convert the original image to RGB PIL format\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(selected_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    \n",
    "    \n",
    "    # Extract embeddings for the original image\n",
    "    original_fuzzyarcface1_embedding = extract_embedding(fuzzyarcface1_model, pil_image, device)\n",
    "    original_arcface_embedding = extract_embedding(arcface_model, pil_image, device)\n",
    "    original_fuzzyarcface2_embedding = extract_embedding(fuzzyarcface2_model, pil_image, device)\n",
    "    original_fuzzyarcface3_embedding = extract_embedding(fuzzyarcface3_model, pil_image, device)\n",
    "\n",
    "    # Obfuscation levels\n",
    "    #obfuscation_levels = [0.05, 0.10, 0.15, 0.20, 0.25, 0.30]\n",
    "\n",
    "    # Generate and save obfuscated images, and compute similarity\n",
    "    for obfuscation_level in obfuscation_levels:\n",
    "        obfuscated_image = obfuscate_image(pil_image.copy(), obfuscation_level)\n",
    "        obfuscated_image_name = f\"{class_name}.obf{int(obfuscation_level*100)}.png\"\n",
    "        obfuscated_image.save(os.path.join(class_output_dir, obfuscated_image_name))\n",
    "\n",
    "        # Extract embeddings for the obfuscated image\n",
    "        obfuscated_fuzzyarcface1_embedding = extract_embedding(fuzzyarcface1_model, obfuscated_image, device)\n",
    "        obfuscated_arcface_embedding = extract_embedding(arcface_model, obfuscated_image, device)\n",
    "        obfuscated_fuzzyarcface2_embedding = extract_embedding(fuzzyarcface2_model, obfuscated_image, device)\n",
    "        obfuscated_fuzzyarcface3_embedding = extract_embedding(fuzzyarcface3_model, obfuscated_image, device)\n",
    "\n",
    "#         # Compute cosine similarities\n",
    "#         fuzzyarcface1_similarity = cosine_similarity([original_fuzzyarcface1_embedding], [obfuscated_fuzzyarcface1_embedding])[0][0] * 100\n",
    "#         arcface_similarity = cosine_similarity([original_arcface_embedding], [obfuscated_arcface_embedding])[0][0] * 100\n",
    "#         fuzzyarcface2_similarity = cosine_similarity([original_fuzzyarcface2_embedding], [obfuscated_fuzzyarcface2_embedding])[0][0] * 100\n",
    "#         fuzzyarcface3_similarity = cosine_similarity([original_fuzzyarcface3_embedding], [obfuscated_fuzzyarcface3_embedding])[0][0] * 100\n",
    "        # Compute cosine similarities\n",
    "        fuzzyarcface1_similarity = cosine_similarity(original_fuzzyarcface1_embedding, obfuscated_fuzzyarcface1_embedding)\n",
    "        arcface_similarity = cosine_similarity(original_arcface_embedding, obfuscated_arcface_embedding)\n",
    "        fuzzyarcface2_similarity = cosine_similarity(original_fuzzyarcface2_embedding, obfuscated_fuzzyarcface2_embedding)\n",
    "        fuzzyarcface3_similarity = cosine_similarity(original_fuzzyarcface3_embedding, obfuscated_fuzzyarcface3_embedding)\n",
    "        \n",
    "\n",
    "\n",
    "        # Append results to DataFrame\n",
    "        results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "            'Class': class_name,\n",
    "            'Obfuscation Level': obfuscation_level * 100,\n",
    "            'FuzzyArcFace1 Similarity': fuzzyarcface1_similarity,\n",
    "            'ArcFace Similarity': arcface_similarity,\n",
    "            'FuzzyArcFace2 Similarity': fuzzyarcface2_similarity,\n",
    "            'FuzzyArcFace3 Similarity': fuzzyarcface3_similarity\n",
    "        }])], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5791475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('cfp_similarity_results.csv', index=False)\n",
    "\n",
    "print(\"Analysis complete for CFP celebrities face db. Results saved to 'cfp_similarity_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74535e75",
   "metadata": {},
   "source": [
    "CROSS AGE CELEBRITY DATASET https://www.v7labs.com/open-datasets/cacd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf23b0",
   "metadata": {},
   "source": [
    "For each class, compute the embeddings for all images.\n",
    "Compare each image's embeddings with every other image's embeddings within the same class.\n",
    "Calculate and store the cosine similarity for each comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6e6e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and device\n",
    "base_dir_cacd = 'CACD2000/CACD2000'\n",
    "output_dir = 'CACD2000/CACD2000/Processed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0249951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare results dataframe\n",
    "results_df = pd.DataFrame(columns=['Class', 'Image1', 'Image2', 'FuzzyArcFace1 Similarity', 'ArcFace Similarity', 'FuzzyArcFace2 Similarity', 'FuzzyArcFace3 Similarity'])\n",
    "\n",
    "# Get all image paths\n",
    "image_files = glob(os.path.join(base_dir_cacd, '*.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f27dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group images by celebrity name (class)\n",
    "class_images = {}\n",
    "for image_path in image_files:\n",
    "    image_name = os.path.basename(image_path)\n",
    "    class_name = image_name.split('_')[1]  # Assuming the format is <id>_<celebrity_name>_<other>.jpg\n",
    "    if class_name not in class_images:\n",
    "        class_images[class_name] = []\n",
    "    class_images[class_name].append(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3956270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each class\n",
    "for class_name, images in class_images.items():\n",
    "    if len(images) < 2:\n",
    "        print(f\"Not enough images for class: {class_name}\")\n",
    "        continue\n",
    "\n",
    "    embeddings = {'FuzzyArcFace1': [], 'ArcFace': [], 'FuzzyArcFace2': [], 'FuzzyArcFace3': []}\n",
    "    image_names = []\n",
    "\n",
    "    # Compute embeddings for all images in the class\n",
    "    for image_path in images:\n",
    "        image_name = os.path.basename(image_path)\n",
    "        selected_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        \n",
    "                        # Check if the image was read correctly\n",
    "        if selected_image is None:\n",
    "            print(f\"Error reading image: {image_path}\")\n",
    "            continue\n",
    "            \n",
    "        pil_image = Image.fromarray(cv2.cvtColor(selected_image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Extract embeddings\n",
    "        fuzzyarcface1_embedding = extract_embedding(fuzzyarcface1_model, pil_image, device)\n",
    "        arcface_embedding = extract_embedding(arcface_model, pil_image, device)\n",
    "        fuzzyarcface2_embedding = extract_embedding(fuzzyarcface2_model, pil_image, device)\n",
    "        fuzzyarcface3_embedding = extract_embedding(fuzzyarcface3_model, pil_image, device)\n",
    "\n",
    "        embeddings['FuzzyArcFace1'].append(fuzzyarcface1_embedding)\n",
    "        embeddings['ArcFace'].append(arcface_embedding)\n",
    "        embeddings['FuzzyArcFace2'].append(fuzzyarcface2_embedding)\n",
    "        embeddings['FuzzyArcFace3'].append(fuzzyarcface3_embedding)\n",
    "        image_names.append(image_name)\n",
    "    \n",
    "    # Compare each image with every other image in the same class\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i + 1, len(images)):\n",
    "            image1_name = image_names[i]\n",
    "            image2_name = image_names[j]\n",
    "\n",
    "            # Compute cosine similarities\n",
    "            fuzzyarcface1_similarity = cosine_similarity(embeddings['FuzzyArcFace1'][i], embeddings['FuzzyArcFace1'][j]) * 100\n",
    "            arcface_similarity = cosine_similarity(embeddings['ArcFace'][i], embeddings['ArcFace'][j]) * 100\n",
    "            fuzzyarcface2_similarity = cosine_similarity(embeddings['FuzzyArcFace2'][i], embeddings['FuzzyArcFace2'][j]) * 100\n",
    "            fuzzyarcface3_similarity = cosine_similarity(embeddings['FuzzyArcFace3'][i], embeddings['FuzzyArcFace3'][j]) * 100\n",
    "\n",
    "            # Append results to DataFrame\n",
    "            results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "                'Class': class_name,\n",
    "                'Image1': image1_name,\n",
    "                'Image2': image2_name,\n",
    "                'FuzzyArcFace1 Similarity': fuzzyarcface1_similarity,\n",
    "                'ArcFace Similarity': arcface_similarity,\n",
    "                'FuzzyArcFace2 Similarity': fuzzyarcface2_similarity,\n",
    "                'FuzzyArcFace3 Similarity': fuzzyarcface3_similarity\n",
    "            }])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "results_df.to_csv('cacd2000_similarity_results.csv', index=False)\n",
    "\n",
    "print(\"Analysis complete for CACD2000 celebrities face db. Results saved to 'cacd2000_similarity_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2581900b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7274d833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc80951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "778e0359",
   "metadata": {},
   "source": [
    "MIT CIBCL FACE RECOGNITION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b2f29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
